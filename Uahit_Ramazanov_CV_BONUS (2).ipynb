{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Uahit Ramazanov CV BONUS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5933c4d8123437eacd48942c5e3ae80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_369493f4ce234ff49b547b3a73806412",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_906d31a9316c4ae58320978d7e1b209e",
              "IPY_MODEL_fa46936e9be34f758bcc279eaff5f3eb",
              "IPY_MODEL_54d1ce1f20e849108d23b431f8da1fa6"
            ]
          }
        },
        "369493f4ce234ff49b547b3a73806412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "906d31a9316c4ae58320978d7e1b209e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_550db43057284a53aa290589bdcf213a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_553e2be6daea40448c0f60e601ccce71"
          }
        },
        "fa46936e9be34f758bcc279eaff5f3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e12cc262ddc44239dd67fe9b3a58707",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55e119f55c6241a686fe9796a8e87aeb"
          }
        },
        "54d1ce1f20e849108d23b431f8da1fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ccce7abb4c54400a34e5e38f34ae495",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 55905131.10it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc76eac53e834cb19d5699034996f69b"
          }
        },
        "550db43057284a53aa290589bdcf213a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "553e2be6daea40448c0f60e601ccce71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e12cc262ddc44239dd67fe9b3a58707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55e119f55c6241a686fe9796a8e87aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ccce7abb4c54400a34e5e38f34ae495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc76eac53e834cb19d5699034996f69b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1tqZNdWmvQN"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary\n",
        "import keras\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt  \n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_hcyvMtnbSA"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  # Functional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "a5933c4d8123437eacd48942c5e3ae80",
            "369493f4ce234ff49b547b3a73806412",
            "906d31a9316c4ae58320978d7e1b209e",
            "fa46936e9be34f758bcc279eaff5f3eb",
            "54d1ce1f20e849108d23b431f8da1fa6",
            "550db43057284a53aa290589bdcf213a",
            "553e2be6daea40448c0f60e601ccce71",
            "2e12cc262ddc44239dd67fe9b3a58707",
            "55e119f55c6241a686fe9796a8e87aeb",
            "9ccce7abb4c54400a34e5e38f34ae495",
            "cc76eac53e834cb19d5699034996f69b"
          ]
        },
        "id": "KEH8UgeFmvRu",
        "outputId": "579d6c72-de9e-4e91-f816-74fd2072b136"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5933c4d8123437eacd48942c5e3ae80",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PlPNDb5B1vE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5f66ae-3caa-4eea-f305-fe17dea0e8d0"
      },
      "source": [
        "trainset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "-IxjpMXfmvRy",
        "outputId": "7f5697e3-2f11-4164-fd4f-47c1a0a8f148"
      },
      "source": [
        "# случайный индекс от 0 до размера тренировочной выборки\n",
        "i = np.random.randint(low=0, high=50000)\n",
        "\n",
        "plt.imshow(trainloader.dataset.data[i], cmap='gray');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC1Sd1sGB1vG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f06b7e1a-2568-4649-bfb0-b0bdc26f9cb2"
      },
      "source": [
        "trainloader.dataset.data[i].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdTa6-E3HNlN",
        "outputId": "dcedab3d-b058-409d-8e27-557269517689"
      },
      "source": [
        "next(iter(trainloader))[0].shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4gFpJ19lTlN",
        "outputId": "0a51b378-eaf7-4a15-b269-b81e2d717c17"
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "val_size = 5000\n",
        "train_size = len(trainset) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki4eNLwrlgu5",
        "outputId": "f22e554c-5e01-466a-c850-6e007678b730"
      },
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "batch_size=64\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucUsexoVlliL"
      },
      "source": [
        "@torch.no_grad()\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        accu = accuracy(out,labels)\n",
        "        return loss,accu\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'Loss': loss.detach(), 'Accuracy': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['Loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['Accuracy'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'Loss': epoch_loss.item(), 'Accuracy': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch :\",epoch + 1)\n",
        "        print(f'Train Accuracy:{result[\"train_accuracy\"]*100:.2f}% Validation Accuracy:{result[\"Accuracy\"]*100:.2f}%')\n",
        "        print(f'Train Loss:{result[\"train_loss\"]:.4f} Validation Loss:{result[\"Loss\"]:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbdpM-w2lqDT"
      },
      "source": [
        "class Cifar10CnnModel(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
        "            nn.BatchNorm2d(64),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
        "            nn.BatchNorm2d(256),\n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(256*4*4, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hyv2BKUluSA"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in data_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(model, train_loader, val_loader,epochs=10,learning_rate=0.001):\n",
        "    best_valid = None\n",
        "    history = []\n",
        "    optimizer = torch.optim.Adam(model.parameters(), learning_rate,weight_decay=0.0005)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        train_accuracy = []\n",
        "        for batch in tqdm(train_loader):\n",
        "            loss,accu = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            train_accuracy.append(accu)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['train_accuracy'] = torch.stack(train_accuracy).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        if(best_valid == None or best_valid<result['Accuracy']):\n",
        "            best_valid=result['Accuracy']\n",
        "            torch.save(model.state_dict(), 'cifar10-cnn.pth')\n",
        "        history.append(result)\n",
        "    return history\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6klXVbTxmPYp"
      },
      "source": [
        "imgClass =  ImageClassificationBase()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j3-CTAcmcJx"
      },
      "source": [
        "model = Cifar10CnnModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA1rE4k-mzn1"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "X9so0-j4lyG5",
        "outputId": "1b69faa1-6cfb-403a-f500-3bb9bfbaa07d"
      },
      "source": [
        "history = fit(model, train_dl, val_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/704 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "100%|██████████| 704/704 [13:35<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1\n",
            "Train Accuracy:57.52% Validation Accuracy:67.46%\n",
            "Train Loss:1.1797 Validation Loss:0.9138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 704/704 [13:14<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 2\n",
            "Train Accuracy:73.56% Validation Accuracy:71.28%\n",
            "Train Loss:0.7595 Validation Loss:0.8491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 704/704 [13:16<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 3\n",
            "Train Accuracy:78.97% Validation Accuracy:78.07%\n",
            "Train Loss:0.6082 Validation Loss:0.6352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 704/704 [13:19<00:00,  1.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 4\n",
            "Train Accuracy:82.35% Validation Accuracy:79.23%\n",
            "Train Loss:0.5111 Validation Loss:0.6183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 704/704 [13:18<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 5\n",
            "Train Accuracy:84.69% Validation Accuracy:79.91%\n",
            "Train Loss:0.4453 Validation Loss:0.6053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 52/704 [01:00<12:38,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b31ca25398ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-38e13dcba2cd>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader, val_loader, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NBQvUzBqjqu",
        "outputId": "f5118980-0f88-4cd9-e12c-51c40a303c40"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        y_pred = model(images)#.view(4, -1))\n",
        "        _, predicted = torch.max(y_pred, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of plane : 82 %\n",
            "Accuracy of   car : 82 %\n",
            "Accuracy of  bird : 81 %\n",
            "Accuracy of   cat : 64 %\n",
            "Accuracy of  deer : 66 %\n",
            "Accuracy of   dog : 78 %\n",
            "Accuracy of  frog : 83 %\n",
            "Accuracy of horse : 80 %\n",
            "Accuracy of  ship : 96 %\n",
            "Accuracy of truck : 82 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6TMXTYE4OUx",
        "outputId": "e29c0be2-f867-41d2-d9e4-36727cc1e77c"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 81 %\n"
          ]
        }
      ]
    }
  ]
}